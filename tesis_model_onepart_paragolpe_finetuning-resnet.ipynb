{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14008902-6e3e-4112-bafa-9b3a9d5f2529",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Introducción\n",
    "\n",
    "Entrenamiento de modelo preentrenado para resolver el problema de predecir el ángulo del auto en base a la imagen.\n",
    "\n",
    "Fuertemente basado en:\n",
    "- https://towardsdatascience.com/a-practical-example-in-transfer-learning-with-pytorch-846bb835f2db\n",
    "- https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f16c12-cf8c-4db2-9d6d-c0b99b03efcd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77316db9-9ea9-4fb0-9b5c-fbfff89a2e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'metrics_helper' from '/Users/fcuevas/Documents/fing/tesis/jupyters/metrics_helper.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchmetrics import MetricCollection, Accuracy, Precision, Recall, F1, ConfusionMatrix\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import importlib\n",
    "import training_helper\n",
    "from dataset_modules.one_part_dataset import OnePartDataset\n",
    "import metrics_helper\n",
    "\n",
    "importlib.reload(training_helper)\n",
    "importlib.reload(metrics_helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7689a1f9-cd38-4223-b0dd-84f6a81b2f16",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39af4ad1-f511-49a7-afff-d3cb96f91846",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"one_part_model\"\n",
    "EXPERIMENT_NAME = \"resnet50_paragolpe_fine_tuning\"\n",
    "FEATURE_EXTRACTION = False\n",
    "\n",
    "device_string = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_string)\n",
    "\n",
    "if device_string == \"cuda\":\n",
    "    print(\"Usando GPU!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f74e279b-ef85-4996-a468-3d9d88a94eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(\"./trained_models/{}/{}/asd.txt\".format(MODEL_NAME, EXPERIMENT_NAME)), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bda96ff-2ee1-4333-9185-929c4ac7aaa5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Se crea un dataset de tipo `ImageFolder` que se toma de la carpeta `dataset`, donde cada subcarpeta es una de las categorías a entrenar. \n",
    "\n",
    "Automáticamente mapea categorías a números `dataset.class_to_idx`.\n",
    "\n",
    "Finalmente se hace el split en train y test en 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b1ed65c-a40d-4333-b362-55095ac2704d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- CLASS DISTRIBUTION -----\n",
      "Class: no_paragolpe_delantero, #738, 55.57%\n",
      "Class: paragolpe_delantero_roto, #331, 24.92%\n",
      "Class: paragolpe_delantero_sano, #259, 19.50%\n"
     ]
    }
   ],
   "source": [
    "dataset = OnePartDataset(\n",
    "    \"Paragolpe Delantero\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "classes = dataset.classes\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'test': len(test_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf99192-6af0-42d5-8bfe-21eded216cad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loaders\n",
    "Luego, se crean loaders para cada uno de los conjuntos. Los loaders permiten procesar los datos de a batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d53518f5-cf88-4d5b-865b-4a173e0b7d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'test': test_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7bcfec-2b9a-4b27-97d1-991c2eaab42e",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "\n",
    "En este step se carga el modelo pre-entrenado. Para este ejemplo se utiliza el modelo alexnet por su simplicidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be52f59-d26d-46ee-81c0-2a5c037de937",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ¿Finetuning o Feature extraction?\n",
    "\n",
    "- **Finetuning:** Consiste en incializar la red con los pesos pre-entrenados, y re-entrenar toda la red (ajustar los parámetros de todas las capas) con el dataset custom.\n",
    "- **Feature extraction:** La diferencia con lo anterior es que se congelan las capas convolucionales, de modo que el entrenamiento no las cambie con nuestros datos.\n",
    "\n",
    "En ambos casos pisamos la capa de **clasificador** por una capa nueva con 8 categorías, porque el modelo pre-entrenado tiene 1000 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67a52abb-79e3-4f66-9246-028684e983d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fde330fe-b782-4103-bad3-ac9f34578cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f979bc03-3c5e-4c3b-939e-662d6309283d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = len(classes)\n",
    "\n",
    "if FEATURE_EXTRACTION:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "model.fc = torch.nn.Linear(2048, NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "# Tensorboard metrics writer\n",
    "writer = SummaryWriter(log_dir='./trained_models/{}/tensorboard/{}'.format(MODEL_NAME, EXPERIMENT_NAME + '-' + datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n",
    "\n",
    "# Función de error\n",
    "criterion = F.cross_entropy\n",
    "\n",
    "# Optimizador\n",
    "parameters_to_update = model.parameters()\n",
    "\n",
    "if FEATURE_EXTRACTION:\n",
    "    parameters_to_update = model.classifier[6].parameters()\n",
    "\n",
    "optimizer = optim.SGD(parameters_to_update, lr=0.001, momentum=0.9)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29bad071-f55b-4dd0-a0ac-23419dbd48d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x13faca670>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fcuevas/miniconda3/envs/tesis/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/fcuevas/miniconda3/envs/tesis/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1301, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/fcuevas/miniconda3/envs/tesis/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Users/fcuevas/miniconda3/envs/tesis/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Users/fcuevas/miniconda3/envs/tesis/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/fcuevas/miniconda3/envs/tesis/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5z/f899gz4j2lb9wdtgkkvvr1t8qxs155/T/ipykernel_2660/3673685590.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = training_helper.train_model(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/fing/tesis/jupyters/training_helper.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, dataloaders, dataset_sizes, device, writer, num_classes, csv_folder, main_metric, num_epochs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.9/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.9/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.9/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 442\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = training_helper.train_model(\n",
    "    model, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    dataloaders, \n",
    "    dataset_sizes, \n",
    "    device, \n",
    "    writer, \n",
    "    NUM_CLASSES,\n",
    "    'trained_models/{}/{}'.format(MODEL_NAME, EXPERIMENT_NAME),\n",
    "    main_metric='macro_f1', \n",
    "    num_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ed16a25-64c7-4c77-bc4c-f7d720b10ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BEST_MODEL_PATH = './trained_models/{}/{}/best_model.pth'.format(MODEL_NAME, EXPERIMENT_NAME)\n",
    "os.makedirs(os.path.dirname(BEST_MODEL_PATH), exist_ok=True)\n",
    "torch.save(model.state_dict(), BEST_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e0cc79-c8f8-45ee-9c14-5c5596ac46f5",
   "metadata": {},
   "source": [
    "## Evaluación final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1a74753-1983-4a76-bb21-edcaee378a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_modules.common import pil_loader\n",
    "model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "metrics = metrics_helper.init_metrics(device, NUM_CLASSES)\n",
    "tensorboard_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "total_loss = 0.0\n",
    "\n",
    "for i, (images, labels, imgs_path) in enumerate(test_loader):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        metrics(outputs, labels)\n",
    "        \n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        for sampleno in range(images.shape[0]):\n",
    "            if(labels[sampleno] != predictions[sampleno]):\n",
    "                name = 'Misclasified_Predicted-{}_Classified-{}/{}'.format(classes[predictions[sampleno]], classes[labels[sampleno]], imgs_path[sampleno])\n",
    "                \n",
    "                writer.add_image(name, tensorboard_transforms(pil_loader('./dataset_modules/imgs/' + imgs_path[sampleno])))\n",
    "                writer.flush()\n",
    "        \n",
    "total_loss /= dataset_sizes[\"test\"]\n",
    "\n",
    "metrics_result = metrics.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7639ae59-d411-40e9-8c71-09e332db6ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- GENERAL METRICS -------------------------\n",
      "\n",
      "Loss 0.5218959426879883\n",
      "Micro Accuracy 0.800000011920929\n",
      "Macro Accuracy 0.6841511130332947\n",
      "Macro Precision 0.6761487722396851\n",
      "Macro Recall 0.6841511130332947\n",
      "Macro F1 0.6841511130332947\n",
      "\n",
      "------------------------- PER CLASS METRICS -------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paragolpe_delantero_roto</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paragolpe_delantero_sano</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_paragolpe_delantero</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.951613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      class  accuracy  precision    recall        f1\n",
       "0  paragolpe_delantero_roto  0.571429   0.571429  0.571429  0.571429\n",
       "1  paragolpe_delantero_sano  0.529412   0.473684  0.529412  0.529412\n",
       "2    no_paragolpe_delantero  0.951613   0.983333  0.951613  0.951613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "macro_metrics = metrics_helper.generate_macro_metrics(metrics_result, total_loss)\n",
    "per_class_metrics = metrics_helper.generate_per_class_metrics(metrics_result, classes)\n",
    "\n",
    "macro_metrics.to_csv('./trained_models/{}/{}/best_model_macro_metrics.csv'.format(MODEL_NAME, EXPERIMENT_NAME), index=False)\n",
    "per_class_metrics.to_csv('./trained_models/{}/{}/best_model_per_class_metrics.csv'.format(MODEL_NAME, EXPERIMENT_NAME), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40cf4817-9bc4-4660-bfbf-8ccd9dd63c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApoAAAGcCAYAAAB5vQB/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwwklEQVR4nO3dedwWdb3/8ff7BpVNUVyIkyimqJkeUXHLJczlUGaKmuRSYB05pyw1NZdSj+UvUyuz446l0tFIMUnEc1xCEXEFQcEFs6PgEkp6XNBEET6/P+Z7d4+398499zUDryeP63HPNdfMdz4z13Dfn/vzmbluR4QAAACAzlZX6wAAAACwciLRBAAAQCFINAEAAFAIEk0AAAAUgkQTAAAAhehe6wCwcnjshcV8fAE6Va/Vu9U6BKxkNlqvV61DwEqkR3e5K7fXc7vvdNrP2fdmX9JlsVPRBAAAQCGoaAIAAJSdq1kbJNEEAAAoO3dpp77TVDM9BgAAQOlR0QQAACg7WucAAAAoBK1zAAAAoAEVTQAAgLKjdQ4AAIBC0DoHAAAAGlDRBAAAKDta5wAAACgErXMAAACgARVNAACAsqN1DgAAgELQOgcAAAAaUNEEAAAoO1rnAAAAKAStcwAAAKABFU0AAICyo3UOAACAQlQ00axm1AAAACg9KpoAAABlV1fNm4FINAEAAMqO1jkAAADQgIomAABA2VX0czRJNAEAAMqO1jkAAADQgIomAABA2dE6BwAAQCFonQMAAAANqGgCAACUHa1zAAAAFILWOQAAANCAiiYAAEDZ0ToHAABAIWidAwAAAA2oaAIAAJQdrXMAAAAUgtY5AAAA0ICKJgAAQNlVtKJJogkAAFB2XKMJAACAQlS0olnNqAEAAFB6VDQBAADKjtY5AAAACkHrHAAAAGhARRMAAKDsaJ0DAACgCK5ooknrHAAAAIWgogkAAFByVa1okmgCAACUXTXzTFrnAAAAKAYVTQAAgJKjdQ4AAIBCdHWiaXu+pMWSlkn6MCKG2u4n6QZJgyTNl3RYRLzR0ji0zgEAANCUvSJiSEQMTc9PkzQlIgZLmpKet4hEEwAAoORsd9pjBRwoaVyaHifpoNZWINEEAAAouc5MNG2PsT0z9xjTxCZD0p22H8293j8iFkpS+rpBa3FzjSYAAMAqJCLGShrbymK7RcRfbW8g6S7b8zqyrUpXNG2/U+DYw2xPXtFlWln/Bx1dtzPZHmT7iFrHsbK5/Oc/0jFf2VcnHXPYP+ZdN/ZX+t43DtH3x3xVPz/7ZL37zuIaRoiqm3TT73Ts6EP17VGH6JYJ19c6HFTc/fdN05f3/xd9afi++s1VreUg6HLuxEcbRMRf09dFkiZK2knSq7YHSFL6uqi1cbo00bRNBfWj2p1o2u7WkQ0509z7PUgSiWYn+9x+B+j0cy/+yLxttt9ZP7/qBv1s7O814JMb6Y/jr6lRdKi6Bc/9RXdMvlm/uOK/dPFvbtCMB6fpry8tqHVYqKhly5bp3J/8WJdd8WtNnHSbbv/vyfrfv/yl1mEhpyuv0bTd2/aa9dOS9pP0hKRJkkalxUZJuqW1sdqdaKbq1zzb42zPsX2T7V62z7I9w/YTtsc67YntqbbPtX2vpONtH2D7Yduzbf/Jdv+03Pq277I9y/aVthfYXi+9dmIa9wnbJzQR0zDb02xPtP2U7Svqkyrb+9l+MI07wXafFvZteNq36ZIOzs3vbfvqtH+zbR/YxLo72X4gvf6A7S3S/NG2b7Z9u+1nbV+Q5p8nqaftx2xfn+YdZfuRNO/K+qTS9ju2f2z7YUm7tnY8Gr1XT9u+TNIsSQNt/yytN9f2yLToeZL2SNv9nu0etq9Jy8y2vVdz20Dztvrn7dVnzbU+Mm/bobuoW7fs963Bn95Gr7/W6i+DQJNeXPC8tthqG/Xo0VPdunfX1tvuoAen3VPrsFBRT8ydo4EDN9aGAwdqtdVX1/Av7q+p90ypdVionf6Sptt+XNIjkm6LiNuV5Qv72n5W0r7peYs6WtHcQtLYiPhnSW9L+rakSyJix4jYWlJPSV/KLb92RHwuIn4habqkXSJiO0m/l3RKWuY/JN0dEdsrK9FuJEm2d5B0tKSdJe0i6Rjb2zUR006STpK0jaRNJR2cEtUzJO2Txp0p6cSmdsh2D0lXSTpA0h6SPpF7+Ycpth0l7SXpZynDz5snac+0X2dJOjf32hBJI1NsI20PjIjTJL2XPjbgSNufTsvsFhFDlH1u1ZFp/d6SnoiInSW918bjUW8LSb9NcQ1NsWwraZ+0HwOUfTzBfSmWX0o6VpIiYhtJh0sal44POtE9d0zSdjt+ttZhoKI23mRTPfn4LL391ptasuQ9zXxoul5b9Eqtw0JFLXr1VX1iQMOPvQ3699err75aw4jQWFdWNCPiuYjYNj0+ExE/SfNfj4i9I2Jw+vp/rY3V0Vb2ixFxf5q+TtJxkp63fYqkXpL6SXpS0q1pmRty624o6YaU4Kwu6fk0f3dJI9KO3G77jdz8iRHxriTZvllZIji7UUyPRMRzaZnxab0lkraSdH86sKtLerCZfdpS0vMR8Wwa4zpJ9XdZ7Sfpy7ZPTs97KCXCOX2VJWSDld2ptVrutSkR8VYa9ylJG0t6sdH6e0vaQdKMFGtPNVz7sEzSH9p5POotiIiHcuuOj4hlyq6zuFfSjsp+WcjbXdLFkhQR82wvkLS5pDn5hZzdhTZGks746a90yBFHNxMCGrv5+t+oW7du2n3vL9Q6FFTUwEGf0iFHjNaZJ31LPXv21Cabba667lydhI4JxcfmtSUhQdep6vvR0e9Kjc/IkHSZpKER8aLts5UlY/XezU1fLOnCiJhke5iks9P85o5gW49sUzFZ0l0RcXgHx8jHcEhEPPORmantn5wj6Z6IGGF7kKSpudfez00vU9PH3ZLGRcTpTby2JCWH9cu1R/7Yt3XdNi2Xv2vtsRcWN3fs0Mi9d07WrIen68wLLq/sNw6Uw377j9B++4+QJP127MVad/3+rawBNK1//0/olYUNFfFFr76qDTZo9ZNrgFZ1tHW+ke1d0/ThytrhkvRaugby0BbW7Svp5TQ9Kjd/uqTDpOy6SknrpPnTJB3k7DrQ3sqqnvc1Me5OtjdJ12aOTOM9JGk325ulcXvZ3ryZuOZJ2sT2prn9qneHpO/a/7jutKlWdX6/RjezjcaW2q6vfE6RdKizjxGQ7X62N25inbYej6ZMU9a672Z7fUl7Krv2YrGkNRstd2SKY3Nl1dtnhBX22IwHdMsN43TKjy/UGj24GgEr5s03sq7VolcX6oH77tbn9hle44hQVZ/Zehu98MJ8vfTSi1r6wQe6/b9v0+f2+nytw0JOV7bOO1NHK5pPSxpl+0pJz0q6XFliOFfZ376c0cK6Z0uaYPtlZYngJmn+jySNTzeo3CtpoaTFETHL9rXKEiJJ+nVENNUmflDZRanbKEuUJkbEctuj07hrpOXOkPTnxitHxJLUCr7N9mvKEtWt08vnSLpI0pyUbM7XR69BlaQLlLXOT5R0dwv7nzc2jTkrXad5hrIPR62TtFTZtZIfuY20HcejKRMl7SrpcWXV21Mi4hXbr0v6MF30e62y6vQVtudK+lDS6Ih4v5kx0Yxf/eQHemrOo1r81pv61uFf1Fe+PkZ//P21+nDpUv2/U4+VJA3+9NY65oRSfMoVKuinZ56sxW+/qW7du+tbJ5z2sZvPgLbq3r27Tv/hWfrWmH/V8uXLdNCIQ7TZZoNrHRbyKtoAc0T7Op6pLTw53fTTeYFkieCyiPgwVUsvTzfFtGXdYZJOjojGyR+6CK1zdLZeq3fok7yAZm20Xq9ah4CVSI/uXZv6rTtqfKf9nH193OFdFnuZrhzfSNKNqZr3gaRjahwPAABAKVT1mv52J5oRMV8NLeVOk+72buljelpad6o+evNNi2xPVEPLvt6pEXFHR7Zfa7bXVXaNZ2N7R8TrXR0PAADoXKtMorkyiIgRtY6hM6Vkckit4wAAAMhbJRNNAACAKqGiCQAAgGJUM8/s8OdoAgAAAC2iogkAAFBytM4BAABQiKommrTOAQAAUAgqmgAAACVX1YomiSYAAEDJVTXRpHUOAACAQlDRBAAAKLtqFjRJNAEAAMqO1jkAAACQQ0UTAACg5Kpa0STRBAAAKLmqJpq0zgEAAFAIKpoAAABlV82CJokmAABA2dE6BwAAAHKoaAIAAJRcVSuaJJoAAAAlV9VEk9Y5AAAACkFFEwAAoOSqWtEk0QQAACi7auaZtM4BAABQDCqaAAAAJUfrHAAAAIUg0QQAAEAhKppnco0mAAAAikFFEwAAoORonQMAAKAQFc0zaZ0DAACgGFQ0AQAASo7WOQAAAApR0TyT1jkAAACKQUUTAACg5OrqqlnSJNEEAAAoOVrnAAAAQA4VTQAAgJLjrnMAAAAUoqJ5Jq1zAAAAFIOKJgAAQMnROgcAAEAhqppo0joHAABAIahoAgAAlFxFC5okmgAAAGVH6xwAAADIoaIJAABQchUtaJJoAgAAlB2tcwAAAKw0bHezPdv25PS8n+27bD+bvq7T2hgkmgAAACVnd96jHY6X9HTu+WmSpkTEYElT0vMWkWgCAACUnO1Oe7RxextK2l/Sr3OzD5Q0Lk2Pk3RQa+OQaAIAAKxCbI+xPTP3GNPEYhdJOkXS8ty8/hGxUJLS1w1a2xY3AwEAAJRcZ94LFBFjJY1tflv+kqRFEfGo7WErsi0STQAAgJLr4rvOd5P0ZdtflNRD0lq2r5P0qu0BEbHQ9gBJi1obiNY5AAAA/iEiTo+IDSNikKSvSro7Io6SNEnSqLTYKEm3tDYWFU10irV7r1brELCS+WDp8tYXAtph2fKodQhYqXTt51qW5GM0z5N0o+1vSnpB0ldaW4FEEwAAoORq9YHtETFV0tQ0/bqkvduzPq1zAAAAFIKKJgAAQMmVpHXebiSaAAAAJcffOgcAAAByqGgCAACUXEULmiSaAAAAZUfrHAAAAMihogkAAFByVa1okmgCAACUXEXzTFrnAAAAKAYVTQAAgJKjdQ4AAIBCVDTPpHUOAACAYlDRBAAAKDla5wAAAChERfNMWucAAAAoBhVNAACAkquraEmTRBMAAKDkKppn0joHAABAMahoAgAAlBx3nQMAAKAQddXMM2mdAwAAoBhUNAEAAEqO1jkAAAAKUdE8k0QTAACg7KxqZppcowkAAIBCUNEEAAAouaredU6iCQAAUHJVvRmI1jkAAAAKQUUTAACg5Cpa0CTRBAAAKLu6imaatM4BAABQCCqaAAAAJVfRgiaJJgAAQNlx1zkAAACQQ0UTAACg5Cpa0CTRBAAAKDvuOgcAAAByqGgCAACUXDXrmSSaAAAApcdd5wAAAEAOFU0AAICSq6tmQZNEEwAAoOxonQMAAAA5VDQBAABKrqIFTRJNAACAsqN1DgAAAORQ0QQAACg57joHAABAIWidAwAAADlUNAEAAEqumvVMEk0AAIDSq6N1DgAAADSgogkAAFByFS1okmgCAACUHXedAwAAoPJs97D9iO3HbT9p+0dpfj/bd9l+Nn1dp7WxSDQBAABKzu68Rxu8L+nzEbGtpCGShtveRdJpkqZExGBJU9LzFtE6B7rAiwvm69yzTvnH81defklfO+bbOnjkUTWMClU36abf6Y7JNysi9C9fOlgHfuXIWoeECjv7zB/ovmlT1a/fupow8dZah4NGuvKu84gISe+kp6ulR0g6UNKwNH+cpKmSTm1prEpVNG2/0/pSHR57mO3JK7pMK+v/oKProtoGbjxIl4+7UZePu1GXXD1ea/Tood32/Hytw0KFLXjuL7pj8s36xRX/pYt/c4NmPDhNf31pQa3DQoUdcOAIXXL5VbUOA13A9hjbM3OPMU0s0832Y5IWSborIh6W1D8iFkpS+rpBa9sqNNG0TcX0o9qdaNruVkQgqJ3HZj6sAZ8cqP4D/qnWoaDCXlzwvLbYahv16NFT3bp319bb7qAHp91T67BQYTsM3VF9+/atdRhoRme2ziNibEQMzT3GNt5eRCyLiCGSNpS0k+2tOxJ3q4mm7UG259keZ3uO7Zts97J9lu0Ztp+wPdbpdijbU22fa/teScfbPsD2w7Zn2/6T7f5pufXThaSzbF9pe4Ht9dJrJ6Zxn7B9QhMxDbM9zfZE20/ZvsJ2XXptP9sPpnEn2O7Twr4NT/s2XdLBufm9bV+d9m+27QObWHcn2w+k1x+wvUWaP9r2zbZvTxfLXpDmnyepp+3HbF+f5h2VLrZ9LB2Dbmn+O7Z/bPthSbu2djwaxX1bunj3Cdsj0/yW3qvzUwx/tr1Hmt/D9jW256b926u5baL9pv7pdg3bd3itw0DFbbzJpnry8Vl6+603tWTJe5r50HS9tuiVWocFoCC2O+3RHhHxprIW+XBJr9oekOIZoKza2aK2VjS3kDQ2Iv5Z0tuSvi3pkojYMSK2ltRT0pdyy68dEZ+LiF9Imi5pl4jYTtLvJdVfqPYfku6OiO0lTZS0UQp8B0lHS9pZ0i6SjrG9XRMx7STpJEnbSNpU0sEpUT1D0j5p3JmSTmxqh2z3kHSVpAMk7SHpE7mXf5hi21HSXpJ+Zrt3oyHmSdoz7ddZks7NvTZE0sgU20jbAyPiNEnvRcSQiDjS9qfTMrul3xiWSaq/wKq3pCciYmdJ77XxeEjZSfDXiNg2vS+3p/ktvVfdI2InSScoe08k6VhJiohtJB0uaVw6XlhBS5cu1UPT79Wen9+v1qGg4gYO+pQOOWK0zjzpWzr7+8dqk802V113mkgAVlwqBq6dpntK2kdZ3jNJ0qi02ChJt7Q2Vlu/K70YEfen6eskHSfpedunSOolqZ+kJyXVXz18Q27dDSXdkDLf1SU9n+bvLmmEJEXE7bbfyM2fGBHvph28WVkiOLtRTI9ExHNpmfFpvSWStpJ0f8rYV5f0YDP7tKWk5yPi2TTGdZLqr1HYT9KXbZ+cnvdQSoRz+ipLwAYru0B2tdxrUyLirTTuU5I2lvRio/X3lrSDpBkp1p5q+M1gmaQ/tPN4SNJcST+3fb6kyRFxX5q/Vwvv1c3p66OSBuW2ebEkRcQ82wskbS5pTn5jzq7pGCNJP/nFJTpi1DebCAl5Mx6crs0231Lr9Fu31qFgJbDf/iO03/4jJEm/HXux1l2/f40jAlCULr6pZoCyHKdb2vSNETHZ9oOSbrT9TUkvSPpKawO1NdGMJp5fJmloRLxo+2xlyVi9d3PTF0u6MCIm2R4m6ew0v7nabVtruk3FZGUXrB7ewTHyMRwSEc98ZGZq+yfnSLonIkbYHqSsrFzv/dz0MjV9nC1pXESc3sRrSyJiWW65NomIP6eK8Bcl/dT2nZIuUMvvVX2s+TjbtM10TcdYSZr/+pLmjiVypt71Pxq27xdqHQZWEm++8X9ae51+WvTqQj1w3936+WXjah0SgIK0t+W9IiJijqSPdU8j4nVlhbI2a2uCvJHtXdP04cra4ZL0WroG8tAW1u0r6eU0PSo3f7qkw6TsukpJ9R/6OU3SQc6uA+2trOp5nz5uJ9ubOLs2c2Qa7yFJu9neLI3by/bmzcQ1T9ImtjfN7Ve9OyR9N3ctY1Ot6vx+jW5mG40ttV1f+Zwi6VDbG6Rt9LO9cRPrtPV4yPY/Sfp7RFwn6eeStldDUtmW9yq/zSPTmJsrq+Y+0+IaaNWSJe9p1oyHtPuwdv0fBZr10zNP1re/frDOOf14feuE09RnzbVqHRIq7PRTTtToow7XgvnPa/jen9Mfb76p1iFhJdDWiubTkkbZvlLSs5IuV5YYzpU0X9KMFtY9W9IE2y8rSwQ3SfN/JGl8umHlXkkLJS2OiFm2r5X0SFru1xHRVJv4QUnnKbsOcpqy9vJy26PTuGuk5c6Q9OfGK0fEktT6vc32a8oS1fo7qs6RdJGkOSnZnK+PXtcoZZXCcbZPlHR3C/ufNzaNOStdp3mGpDtTsrxU2bWRH/l8knYcDyk7Fj+zvTyN962IeNP2VWrbe1XvMklX2J4r6UNJoyPi/VbWQSt69Oipm26fVuswsBI5/5Krax0CViI/veDCWoeAFtRV8y9QytlncrawQNYWnpxuJOm8DWeJ4LKI+DBVSy9PN8W0Zd1hkk6OiMbJH2qE1jk62wdLl9c6BKxkPtmvZ61DwEqk9+pd+8fHT5w0r9N+zl745S27LPZa3qK4kbILSuskfSDpmBrGAgAAgE7WaqIZEfPV0FLuNOlu7+Y+pqe1dafqozfftMj2RDW07OudGhF3dGT7tWZ7XWXXeDa2d7pQFwAArES68magzrRKfOhaRIyodQydKSWTQ2odBwAA6BpVvUazUn/rHAAAANWxSlQ0AQAAqqyinXMSTQAAgLKrq2imSescAAAAhaCiCQAAUHJVrQySaAIAAJRcRTvnJJoAAABlxzWaAAAAQA4VTQAAgJKraEGTRBMAAKDs+MtAAAAAQA4VTQAAgJKr6s1AJJoAAAAlV9E8k9Y5AAAAikFFEwAAoOSqejMQiSYAAEDJWdXMNGmdAwAAoBBUNAEAAEqO1jkAAAAKUdVEk9Y5AAAACkFFEwAAoORc0Q/SJNEEAAAoOVrnAAAAQA4VTQAAgJKraOecRBMAAKDs6iqaadI6BwAAQCGoaAIAAJRcVW8GItEEAAAouYp2zmmdAwAAoBhUNAEAAEquTtUsaZJoAgAAlBytcwAAACCHiiYAAEDJcdc5AAAACsEHtgMAAAA5VDQBAABKrqIFTRJNAACAsqN1DgAAAORQ0QQAACi5ihY0STQBAADKrqot6KrGDQAAgJKjogkAAFByrmjvnEQTAACg5KqZZtI6BwAAQEGoaAIAAJRcVT9Hk0QTAACg5KqZZtI6BwAAQEGoaAIAAJRcRTvnJJoAAABlV9WPN6J1DgAAgEKQaAIAAJRcXSc+WmN7oO17bD9t+0nbx6f5/WzfZfvZ9HWdtsQNAACAErPdaY82+FDSSRHxaUm7SDrW9laSTpM0JSIGS5qSnreIRBMAAAD/EBELI2JWml4s6WlJn5R0oKRxabFxkg5qbSwSTQAAgJJzZz7sMbZn5h5jmt2uPUjSdpIeltQ/IhZKWTIqaYPW4uaucwAAgJLrzLvOI2KspLFt2GYfSX+QdEJEvN2RGEg00Sn69V691iFgJdOtrpof5YHyWm/n79Y6BKxE3pt9Sa1DKJTt1ZQlmddHxM1p9qu2B0TEQtsDJC1qbRxa5wAAACXXxXedW9JvJD0dERfmXpokaVSaHiXpltbGoqIJAABQcl38ge27SfqapLm2H0vzfiDpPEk32v6mpBckfaW1gUg0AQAA8A8RMV3ZfUNN2bs9Y5FoAgAAlFxVr1on0QQAACi5iv6pcxJNAACAsquraE2Tu84BAABQCCqaAAAAJUfrHAAAAIUwrXMAAACgARVNAACAkqN1DgAAgEJw1zkAAACQQ0UTAACg5GidAwAAoBBVTTRpnQMAAKAQVDQBAABKrqqfo0miCQAAUHJ11cwzaZ0DAACgGFQ0AQAASo7WOQAAAArBXecAAABADhVNAACAkqN1DgAAgEJw1zkAAACQQ0UTAACg5GidAwAAoBDcdQ4AAADkUNEEAAAouYoWNEk0AQAAyq6uor1zWucAAAAoBBVNAACAkqtmPZNEEwAAoPwqmmnSOgcAAEAhqGgCAACUHB/YDgAAgEJU9KZzWucAAAAoBhVNAACAkqtoQZNEEwAAoPQqmmnSOgcAAEAhqGgCAACUHHedAwAAoBDcdQ4AAADkUNEEAAAouYoWNEk0AQAASq+imSatcwAAABSCiiYAAEDJcdc5AAAACsFd5wAAAEAOFU0AAICSq2hBk0QTAACg9CqaadI6BwAAQCGoaAIAAJQcd50DAACgENx1DgAAAORQ0QQAACi5ihY0STQBAABKr6KZJq1zAAAAFIKKJtAFXnlloc7+4Wl6/fXXZFsjDj1Mhx/59VqHhQo7+8wf6L5pU9Wv37qaMPHWWoeDipp324+0+N33tWz5cn24bLl2P/ICbbP5J3XxD7+q3j3X0IK/vq6jfzhOi99dUutQV3ldede57aslfUnSoojYOs3rJ+kGSYMkzZd0WES80dpYVDRbYPta24cWOP582+ut6DItrHuQ7a06Fh06U/du3XTCyadowh9v0zXX3aCbfv87Pfe/f6l1WKiwAw4coUsuv6rWYWAlMHzMr7TLV8/T7kdeIEm6/KwjdMZ/3qIdDztXk+55XN8btXeNI4SU3XXeWY82uFbS8EbzTpM0JSIGS5qSnrdqpUo0bVOh/aiDJLUr0eQYFmO99TfQlp/+jCSpd+/eGvSpTfW3Ra/WOCpU2Q5Dd1Tfvn1rHQZWQoM33kDTH81+Eb77oXk6aO8htQ0IkrJLNDvr0ZqImCbp/xrNPlDSuDQ9TlmO0apOTTRtD7L9tO2rbD9p+07bPW0Psf2Q7Tm2J9pep4Uxptq+yPYDtp+wvVOav1OaNzt93SLNH217gu1bJd1pu4/tKbZn2Z5r+8Dc2Gfanmf7LtvjbZ+c5rcaX6osnm/7kfTYLM1f3/YfbM9Ij91a2Ld10zGZbftK5d5v20elcR+zfaXtbk2s/0fbj6ZjOyY3/x3bP7H9eNqP/rY/K+nLkn6Wxtw0PW5PY9xne8u0/rW2L7R9j6Tz2/N+of3++vLLembe0/rMNtvWOhQAq7iI0K2XfUf3X3+KvnFw9uPrqf9dqC8N20aSdPC+22vD/vwIWNnYHmN7Zu4xpvW11D8iFkpS+rpBW7ZVREVzsKRLI+Izkt6UdIik30o6NSL+WdJcSf/Ryhi9I+Kzkr4t6eo0b56kPSNiO0lnSTo3t/yukkZFxOclLZE0IiK2l7SXpF84MzTFsp2kgyUNza3f1vjejoidJF0i6aI071eSfhkRO6bxf93Cfv2HpOlpHyZJ2kiSbH9a0khJu0XEEEnLJB3ZxPrfiIgdUuzH2V43ze8t6aGI2FbSNEnHRMQDaRvfj4ghEfG/ksZK+m4a42RJl+XG3lzSPhFxUluPR/5EveY3Y1vYbdT7+9/f1aknHacTv3+a+vTpU+twAKziPn/0L/XZI87XQd+5TP82cg/ttv2m+rezr9e/Hban7r/+FPXptYY+WLqs1mFC6tSSZkSMjYihuUdhP8SLaJM+HxGPpelHJW0qae2IuDfNGydpQitjjJey0q3ttWyvLWlNSeNsD5YUklbLLX9XRNSXeC3pXNt7Slou6ZOS+kvaXdItEfGeJKUKqGz3bUd843Nff5mm95G0lRsueljL9poRsbiJ9fdUluQqIm6zXX8R7d6SdpA0I43TU9KiJtY/zvaIND1QWVL/uqQPJE1O8x+VtG/jFW33kfRZSRNysa6RW2RCRCxrz/FIJ+ZYSXp7yfJoahk0+HDpUp164vEa/sUD9Pl99qt1OACghX97S5L0tzfe0aS752jHzwzSRf81RQd8+1JJ0mYbbaAv7PGZWoaIpAR/gvJV2wMiYqHtAWo6T/mYIhLN93PTyySt3YExGictIekcSfdExAjbgyRNzb3+bm76SEnrS9ohIpbani+phzrnE6iiiek6SbvWJ7DtHKOeJY2LiNObW8n2MGVJ7a4R8XfbU5XtlyQtjYj6cZep6fe1TtKbqWLalHebmY9OEBE65+wzNOhTn9KRXx9d63AAQL16rK66Ouudv7+vXj1W1z67bqlzx/6P1l+nj/72xjuyrdOO+RddddP0WoeKcpgkaZSk89LXW9qyUlfcDPSWpDds75Gef03SvS0sL2VtZNneXdJbEfGWpL6SXk6vj25h3b7KbsdfansvSRun+dMlHWC7R6ru7S9Jaey2xjcy9/XBNH2npO/UL2B7SAuxTVNqidv+gqT6C1+mSDrU9gbptX62N260bl9Jb6Qkc0tJu7SwnXqLlVWCFRFvS3re9lfSNmz7YxcJtvN4oI0enz1L/z15kmY+8rCOOGyEjjhshO6/j8OKjjv9lBM1+qjDtWD+8xq+9+f0x5tvqnVIqJgN1l1TU675nh6+4TTdd9339T/3Pam7Hnhahw0fqjl/PEuPTzxTC//2ln57y0O1DhXq2rvObY9XludsYfsl299UlmDua/tZZZ3T89oSd1fdYTxK0hW2e0l6TtLRrSz/hu0HJK0l6Rtp3gXKWucnSrq7hXWvl3Sr7ZmSHlN2baciYobtSZIel7RA0kxlSXB74lvD9sPKEvTD07zjJF1qe46y4zlN0r83s/6PJI23PUtZ8vZCiu0p22cou5mpTtJSScemOOvdLunf03aekdSW//m/l3SV7eMkHaosyb08bWu19PrjTazX3vcLrRiy/Q6a8fjTtQ4DK5GfXnBhrUNAxc1/+XXtPPLjucKl46fq0vFTuz4gtKgrG+cRcXgzL7X7s67c0HEth9QSPjkiZhYwdp+IeCclUNMkjYmIWW1cd76koRHxWmfHtTLgGk10tm51Nb8eCSuZ9Xb+bq1DwErkvdmXdOk3qT+/8vdO+zm7+Sd6dVnsq9pnJo519gHmPZRdE9mmJBMAAKCmKvq7d80STduXSmr8mZO/iohhRW0zIo5YgXUHtXVZ20dLOr7R7Psj4tiObh8AAKy6SnDXeYfULNFcmZOuiLhG0jW1jgMAAKCWVrXWOQAAQOW08W+Ulw6JJgAAQMlVNM/sks/RBAAAwCqIiiYAAEDZVbSkSaIJAABQclW965zWOQAAAApBRRMAAKDkuOscAAAAhahonknrHAAAAMWgogkAAFB2FS1pkmgCAACUHHedAwAAADlUNAEAAEqOu84BAABQiIrmmbTOAQAAUAwqmgAAACVH6xwAAAAFqWamSescAAAAhaCiCQAAUHK0zgEAAFCIiuaZtM4BAABQDCqaAAAAJUfrHAAAAIXgb50DAAAAOVQ0AQAAyq6aBU0STQAAgLKraJ5J6xwAAADFoKIJAABQctx1DgAAgEJw1zkAAACQQ0UTAACg7KpZ0CTRBAAAKLuK5pm0zgEAAFAMKpoAAAAlx13nAAAAKAR3nQMAAAA5VDQBAABKrqqtcyqaAAAAKASJJgAAAApB6xwAAKDkqto6J9EEAAAoOe46BwAAAHKoaAIAAJQcrXMAAAAUoqJ5JokmAABA6VU00+QaTQAAABSCiiYAAEDJVfWucxJNAACAkqvqzUC0zgEAAFAIKpoAAAAlV9GCJokmAABA6VU006R1DgAAgEKQaAIAAJScO/Ffm7ZnD7f9jO2/2D6to3HTOgcAACi5rrzr3HY3SZdK2lfSS5Jm2J4UEU+1dywqmgAAAMjbSdJfIuK5iPhA0u8lHdiRgahoolOs1aOuopcpdy3bYyJibK3jwMqDc6rt3pt9Sa1DqATOqXLq0b3zbgeyPUbSmNyssY3e809KejH3/CVJO3dkW1Q0ga41pvVFgHbhnEJn45xayUXE2IgYmns0/sWiqaQ2OrItEk0AAADkvSRpYO75hpL+2pGBSDQBAACQN0PSYNub2F5d0lclTerIQFyjCXQtrntCZ+OcQmfjnFrFRcSHtr8j6Q5J3SRdHRFPdmQsR3So5Q4AAAC0iNY5AAAACkGiCQAAgEKQaAIAAKAQJJpYpdl+p8Cxh9mevKLLtLL+Dzq6bmeyPcj2EbWOo5Y4l1Altq+1fWiB48+3vd6KLtPCugfZ3qpj0aErkWiiUmzzSQkf1e7kIP0N23ZzprnvGYMkVSrR5Fz6mC47l9B+nK8fc5CkdiWaHMPaINFEl0vVr3m2x9meY/sm271sn2V7hu0nbI+17bT8VNvn2r5X0vG2D7D9sO3Ztv9ku39abn3bd9meZftK2wvqf1u2fWIa9wnbJzQR0zDb02xPtP2U7Svqkyrb+9l+MI07wXafFvZteNq36ZIOzs3vbfvqtH+zbX/sb8ba3sn2A+n1B2xvkeaPtn2z7dttP2v7gjT/PEk9bT9m+/o07yjbj6R5V9YnArbfsf1j2w9L2rW149HovXra9mWSZkkaaPtnab25tkemRc+TtEfa7vds97B9TVpmtu29mtvGiuBcqtS51Nv2bbYfT8uOTPNbeq/OTzH82fYeaX6XnFtNxF//f+Eq20/avtN2T9tDbD+Uzr+JttdpYYypti9K78kTtndK81t6vybYvlXSnbb72J6Szp+5+ffe9pnpfLnL9njbJ6f5rcbnrLJYf6wfsb1Zmr++7T+k92eG7d1a2Ld10zGZbftK5f6yTHPnUqP1/2j70XRsx+Tmv2P7J+m8ech2f9uflfRlST9LY26aHrenMe6zvWVa/1rbF9q+R9L57Xm/0EkiggePLn0oq36FpN3S86slnSypX26Z/5J0QJqeKumy3GvrqOGjuf5V0i/S9CWSTk/Tw9M21pO0g6S5knpL6iPpSUnbpeXeSV+HSVoi6VPKPjPsLkmHpvWnSeqdljtV0lnN7FcPZX8bdrCyb7I3SpqcXjtX0lFpem1Jf07xDMsts5ak7ml6H0l/SNOjJT0nqW/axgJJA/Pxp+lPS7pV0mrp+WWSvp6mQ9JhabrZ49HMe7Vc0i7p+SHp2HST1F/SC5IG5PcjLXeSpGvS9JZpuR6cS6v0uXSIpKtyz/umry29V/Xvxxcl/akrz61mzrUPJQ1Jz2+UdJSkOZI+l+b9WNJFLYwxtf4YSNpT0hNteL9eqj9Gyj77eq00vZ6kv6TzY6ikxyT1lLSmpGclnZyWazI+SddKOjRNz5f0wzT99dx59DtJu6fpjSQ93cK+/afS+SxpfzX8n2npXJovab38eZD24QlJ6+bOt/pz4gJJZzSOPz2fImlwmt5Z0t255SZL6tbS8eBR3IMyMmrlxYi4P01fJ+k4Sc/bPkVSL0n9lP3QujUtc0Nu3Q0l3WB7gKTVJT2f5u8uaYQkRcTttt/IzZ8YEe9Kku2bJe0haXajmB6JiOfSMuPTekuUtWfuT4WW1SU92Mw+bSnp+Yh4No1xnRr+ZvB+kr5cX2VQ9kN+o0br95U0zvZgZd9cV8u9NiUi3krjPiVpY2WJSN7eyn7wz0ix9pS0KL22TNIf2nk86i2IiIdy646PiGWSXnVWGdxR0tuN1tld0sWSFBHzbC+QtLmyb/KdjXOpGufSXEk/t32+skTmvjR/rxbeq5vT10eVJXr12+yqc6ux5yPisVxMm0paOyLuTfPGSZrQyhjjJSkiptley/baypLD5t6vuyLi/9K0JZ1re09lvwB+UtkvfLtLuiUi3pOkVAGV7b7tiG987usv0/Q+krZK54AkrWV7zYhY3MT6eypV3iPittz/mZbOpbzjbI9I0wOV/ZL1uqQPlCWKUnbM9228orPOwGclTcjFukZukQkRsaydxwOdhEQTtdL4LwWEst90h0bEi7bPVvYDtN67uemLJV0YEZNsD5N0dppvNa25+W2Jycq+0R/ewTHyMRwSEc98ZGZq1SbnSLonIkbYHqSs+lHv/dz0MjX9f9eSxkXE6U28tiQlh/XLtUf+2Ld13fZuY0VwLqn851JE/Nn2Dsqqkz+1faeyClVL71V9rPk4u/LcaqzxsVu7A2M0dW609H7lz9cjJa0vaYeIWGp7vrLj1RnHJJqYrpO0a30C284x6rV0LmULZP/39knb+rvtqWo4D5ZGRP24zZ2vdZLejIghzWzi3WbmowtwjSZqZSPbu6bpwyVNT9Ovpd9OW7obsq+kl9P0qNz86ZIOk7Jr4ZS1RaWsXXmQs2v3eiurVN2nj9vJ2d91rZM0Mo33kKTdctcs9bK9eTNxzZO0ie1Nc/tV7w5J37X/cf3Zdq3s1+hmttHYUtv11Y8pkg61vUHaRj/bGzexTluPR1OmSRppu5vt9ZVVMR6RtFhZVSa/3JEpjs2VVdyeUTE4l1rer9HNbKOxQs8l2/8k6e8RcZ2kn0vaXg3JRFveq/w2u+rcas1bkt5wun5U0tck3dvC8lJ2Psj27pLeStXltr5ffSUtSknmXsqq0VJ2fh3g7PrVPspa10pjtzW+kbmv9ZX2OyV9p34B20NaiC3/vnxBDf9n2nIu9ZX0Rkoyt5S0SwvbqfeP7zkR8bayLsZX0jZse9vGK7TzeKCTUNFErTwtaZSzi8aflXS5sm9Mc5VdtzOjhXXPVtYieVnZD+9N0vwfSRrv7CaDeyUtlLQ4ImbZvlZZQiRJv46Iplp7Dyq7qWUbZd80J0bEctuj07j1rZgzlF0X9xERscTZRey32X5N2Tf/rdPL50i6SNKclCDMl/SlRkNcoKx9dqKku1vY/7yxacxZEXGk7TOU3TRQJ2mppGOVXYeXj7Otx6MpEyXtKulxZdWLUyLiFduvS/rQ9uPKrom6TNIVtucqu65tdES838yYK4pzqRrn0jbKbt5Ynsb7VkS8afsqte29qteV51ZbjErx9FJ2/evRrSz/hu0HlF2X+Y00r63v1/WSbrU9U9k1mfMkKSJm2J6k7P/lAkkzlSXB7YlvDWc3eNWp4Reb4yRdanuOsnxhmqR/b2b9+v8zs5T9n3khxfZUG86l2yX9e9rOM8r+L7bm95Kusn2csl9QjpR0edrWaun1x5tYr73vF1YQf+scXS61hiZHxNatLdvOcdeQtCwiPkwVrstbaKU0XneYsovnG//ARolxLqFKnLWET46ImQWM3Sci3kkJ1DRJYyJiVhvXna/s8oXXOjsugIomViYbSbox/db8gaRjahwPqotzCVUz1tkHmPdQdk1km5JMoGhUNIEOsD1RDW3WeqdGxB21iGdF2V5X2bVUje0dEa93dTyrEs6llY/tSyU1/szJX0XENbWIpzPZPlrS8Y1m3x8Rx9YiHpQfiSYAAAAKwV3nAAAAKASJJgAAAApBogkAAIBCkGgCAACgEP8f8woedOpa2roAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(metrics_result['confusion_matrix'], index = classes,\n",
    "                  columns = classes)\n",
    "\n",
    "df_cm = df_cm.applymap(lambda x: x.item())\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "df_cm.to_csv('./trained_models/{}/{}/confusion_matrix.csv'.format(MODEL_NAME, EXPERIMENT_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad851bc-0634-4a73-a56b-38a4b6e8fe33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
